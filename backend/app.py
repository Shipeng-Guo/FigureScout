"""
FigureScout åç«¯æœåŠ¡
æä¾›æ–‡çŒ®æ£€ç´¢å’Œå†…å®¹æå–API
"""
from flask import Flask, request, jsonify
from flask_cors import CORS
import requests
from datetime import datetime, timedelta
import xml.etree.ElementTree as ET
from typing import List, Dict, Optional
import re
from pmc_fetcher import PMCFetcher
from europepmc_searcher import EuropePMCSearcher
from database import ProjectDatabase

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# åˆå§‹åŒ–æ•°æ®åº“
db = ProjectDatabase()

# é…ç½®é«˜è´¨é‡æœŸåˆŠåˆ—è¡¨
HIGH_QUALITY_JOURNALS = [
    "Nature",
    "Nature Cancer",
    "Nature Medicine",
    "Nature Genetics",
    "Nature Biotechnology",
    "Cancer Discovery",
    "Cancer Research",
    "Cancer Cell",
    "Cell",
    "Science",
    "Cell Reports",
    "Nature Communications"
]

class PubMedSearcher:
    """PubMedæ–‡çŒ®æ£€ç´¢ç±»"""
    
    BASE_URL = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
    
    def __init__(self):
        self.email = "figurescout@example.com"  # å»ºè®®è®¾ç½®é‚®ç®±
    
    def search_articles(self, keyword: str, years: int = 3) -> List[str]:
        """
        æœç´¢åŒ…å«å…³é”®è¯çš„æ–‡ç« 
        
        Args:
            keyword: æœç´¢å…³é”®è¯ï¼ˆå¦‚ DepMapï¼‰
            years: æœç´¢è¿‘å‡ å¹´çš„æ–‡ç« 
            
        Returns:
            æ–‡ç« IDåˆ—è¡¨
        """
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=years*365)
        
        # æ„å»ºæœç´¢æŸ¥è¯¢
        date_range = f"{start_date.strftime('%Y/%m/%d')}:{end_date.strftime('%Y/%m/%d')}"
        journal_query = " OR ".join([f'"{journal}"[Journal]' for journal in HIGH_QUALITY_JOURNALS])
        
        # ä¿®å¤ï¼šæ—¥æœŸèŒƒå›´ä¸åº”è¯¥ç”¨å¼•å·æ‹¬èµ·æ¥
        query = f'({keyword}) AND ({journal_query}) AND {date_range}[PDAT]'
        
        # æ‰§è¡Œæœç´¢
        search_url = f"{self.BASE_URL}esearch.fcgi"
        params = {
            "db": "pubmed",
            "term": query,
            "retmax": 100,  # æœ€å¤šè¿”å›100ç¯‡æ–‡ç« 
            "retmode": "xml",
            "sort": "relevance"
        }
        
        try:
            response = requests.get(search_url, params=params, timeout=10)
            response.raise_for_status()
            
            # è§£æXMLå“åº”
            root = ET.fromstring(response.content)
            id_list = root.find(".//IdList")
            
            if id_list is not None:
                return [id_elem.text for id_elem in id_list.findall("Id")]
            return []
        except Exception as e:
            print(f"æœç´¢é”™è¯¯: {e}")
            return []
    
    def fetch_article_details(self, pmid_list: List[str]) -> List[Dict]:
        """
        è·å–æ–‡ç« è¯¦ç»†ä¿¡æ¯
        
        Args:
            pmid_list: PubMed IDåˆ—è¡¨
            
        Returns:
            æ–‡ç« è¯¦æƒ…åˆ—è¡¨
        """
        if not pmid_list:
            return []
        
        fetch_url = f"{self.BASE_URL}efetch.fcgi"
        params = {
            "db": "pubmed",
            "id": ",".join(pmid_list),
            "retmode": "xml"
        }
        
        try:
            response = requests.get(fetch_url, params=params, timeout=30)
            response.raise_for_status()
            
            # è§£ææ–‡ç« ä¿¡æ¯
            root = ET.fromstring(response.content)
            articles = []
            
            for article in root.findall(".//PubmedArticle"):
                article_data = self._parse_article(article)
                if article_data:
                    articles.append(article_data)
            
            return articles
        except Exception as e:
            print(f"è·å–æ–‡ç« è¯¦æƒ…é”™è¯¯: {e}")
            return []
    
    def _parse_article(self, article_elem) -> Optional[Dict]:
        """è§£æå•ç¯‡æ–‡ç« ä¿¡æ¯"""
        try:
            medline = article_elem.find(".//MedlineCitation")
            pmid_elem = medline.find(".//PMID")
            article_node = medline.find(".//Article")
            
            title_elem = article_node.find(".//ArticleTitle")
            abstract_elem = article_node.find(".//Abstract/AbstractText")
            journal_elem = article_node.find(".//Journal/Title")
            pub_date = article_node.find(".//Journal/JournalIssue/PubDate")
            
            # æå–ä½œè€…
            authors = []
            author_list = article_node.find(".//AuthorList")
            if author_list is not None:
                for author in author_list.findall("Author")[:3]:  # åªå–å‰3ä½ä½œè€…
                    lastname = author.find("LastName")
                    forename = author.find("ForeName")
                    if lastname is not None:
                        name = lastname.text
                        if forename is not None:
                            name = f"{forename.text} {name}"
                        authors.append(name)
            
            # æå–å¹´ä»½
            year = ""
            if pub_date is not None:
                year_elem = pub_date.find("Year")
                if year_elem is not None:
                    year = year_elem.text
            
            # è·å–DOI
            doi = None
            article_id_list = article_elem.find(".//PubmedData/ArticleIdList")
            if article_id_list is not None:
                for article_id in article_id_list.findall("ArticleId"):
                    if article_id.get("IdType") == "doi":
                        doi = article_id.text
                        break
            
            return {
                "pmid": pmid_elem.text if pmid_elem is not None else "",
                "title": title_elem.text if title_elem is not None else "",
                "abstract": abstract_elem.text if abstract_elem is not None else "",
                "journal": journal_elem.text if journal_elem is not None else "",
                "year": year,
                "authors": authors,
                "doi": doi,
                "figures": []  # å›¾è¡¨ä¿¡æ¯å°†åœ¨åç»­æ­¥éª¤æå–
            }
        except Exception as e:
            print(f"è§£ææ–‡ç« é”™è¯¯: {e}")
            return None

@app.route('/', methods=['GET'])
def index():
    """æ ¹è·¯å¾„ - æ˜¾ç¤ºAPIä¿¡æ¯"""
    return jsonify({
        "name": "FigureScout API",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "health": "/api/health",
            "search": "/api/search (POST)",
            "article": "/api/article/<pmid> (GET)"
        },
        "frontend": "http://localhost:3000"
    })

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({"status": "ok", "message": "FigureScout API is running"})

@app.route('/api/search', methods=['POST'])
def search_literature():
    """
    æ–‡çŒ®æœç´¢æ¥å£ - ä½¿ç”¨ Europe PMC å…¨æ–‡æœç´¢
    
    Request JSON:
        {
            "keyword": "DepMap",
            "years": 3,
            "fetch_fulltext": true  // å¯é€‰ï¼Œæ˜¯å¦è·å–è¯¦ç»†å…¨æ–‡åˆ†æ
        }
    """
    try:
        data = request.get_json()
        keyword = data.get('keyword', '')
        years = data.get('years', 3)
        fetch_fulltext = data.get('fetch_fulltext', True)  # é»˜è®¤è·å–è¯¦ç»†å…¨æ–‡åˆ†æ
        max_fulltext = data.get('max_fulltext', 20)  # æ¸è¿›å¼åŠ è½½ï¼šåˆæ¬¡åªå¤„ç†20ç¯‡
        
        if not keyword:
            return jsonify({"error": "å…³é”®è¯ä¸èƒ½ä¸ºç©º"}), 400
        
        print(f"\n{'='*60}")
        print(f"æœç´¢å…³é”®è¯: {keyword}")
        print(f"æ—¶é—´èŒƒå›´: è¿‘{years}å¹´")
        print(f"åˆæ¬¡å…¨æ–‡å¤„ç†: {max_fulltext}ç¯‡")
        print(f"ä½¿ç”¨ Europe PMC å…¨æ–‡æœç´¢ï¼ˆåŒ…æ‹¬æ–¹æ³•ã€ç»“æœç« èŠ‚ï¼‰")
        print(f"{'='*60}\n")
        
        # ä½¿ç”¨ Europe PMC å…¨æ–‡æœç´¢
        # æ ¹æ®æ—¶é—´èŒƒå›´åŠ¨æ€è°ƒæ•´è¿”å›æ•°é‡
        # æ—¶é—´è¶Šé•¿ï¼Œå¯èƒ½çš„æ–‡ç« è¶Šå¤š
        page_size = min(50 * years, 500)  # æ¯å¹´50ç¯‡ï¼Œæœ€å¤š500ç¯‡
        
        europepmc_searcher = EuropePMCSearcher()
        articles = europepmc_searcher.search_fulltext(
            keyword=keyword,
            years=years,
            journals=HIGH_QUALITY_JOURNALS,
            page_size=page_size
        )
        
        if not articles:
            print("âš ï¸ Europe PMC æœªæ‰¾åˆ°æ–‡ç« ï¼Œå°è¯• PubMed æœç´¢...")
            # é™çº§åˆ° PubMed æœç´¢
            searcher = PubMedSearcher()
            pmid_list = searcher.search_articles(keyword, years)
            if pmid_list:
                articles = searcher.fetch_article_details(pmid_list)
                for article in articles:
                    article['relevance'] = analyze_relevance(article, keyword)
                    article['keyword'] = keyword
                    article['has_fulltext'] = False
        
        if not articles:
            return jsonify({
                "keyword": keyword,
                "total": 0,
                "fulltext_available": 0,
                "results": []
            })
        
        print(f"âœ… Europe PMC æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« \n")
        
        # ğŸ”§ ä¿®å¤ï¼šå…ˆæŒ‰ç›¸å…³æ€§æ’åºï¼Œç¡®ä¿å¤„ç†çš„æ˜¯æœ€ç›¸å…³çš„æ–‡ç« 
        articles.sort(key=lambda x: x.get('relevance', {}).get('score', 0), reverse=True)
        
        # è·å–è¯¦ç»†çš„å…¨æ–‡åˆ†æï¼ˆPMC XML è§£æï¼‰
        if fetch_fulltext:
            pmc_fetcher = PMCFetcher()
            max_process = min(len(articles), max_fulltext)
            print(f"å¼€å§‹è·å–è¯¦ç»†å…¨æ–‡åˆ†æï¼ˆå·²æ’åºï¼‰ï¼Œå…± {max_process} ç¯‡...\n")
            
            processed_count = 0
            for idx, article in enumerate(articles[:max_process], 1):
                # ä¿®æ”¹ï¼šä¸å†ç›´æ¥è·³è¿‡æ²¡æœ‰ pmc_id çš„æ–‡ç« 
                # pmc_fetcher.get_fulltext_info ä¼šå°è¯•é€šè¿‡ PMID è·å– PMC ID
                article['fulltext_processed'] = True  # æ ‡è®°å·²å°è¯•å¤„ç†
                
                try:
                    # è·å–è¯¦ç»†çš„ç« èŠ‚åˆ†æã€å›¾è¡¨ç­‰
                    # æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å†…éƒ¨ä¼šå…ˆé€šè¿‡ PMID è·å– PMC ID
                    fulltext_info = pmc_fetcher.get_fulltext_info(article['pmid'], keyword)
                    
                    if fulltext_info and fulltext_info.get('fulltext'):
                        # æˆåŠŸè·å–å…¨æ–‡
                        article['fulltext'] = fulltext_info['fulltext']
                        article['has_fulltext'] = True  # åªæœ‰æˆåŠŸè·å–æ‰è®¾ä¸ºTrue
                        article['pmc_id'] = fulltext_info.get('pmc_id') or article.get('pmc_id')
                        article['pmc_available'] = True
                        
                        mentions = fulltext_info['fulltext']['total_mentions']
                        pmc_id = article.get('pmc_id', 'N/A')
                        print(f"[{idx}/{max_process}] âœ… {pmc_id}: æ‰¾åˆ° {mentions} å¤„æåŠ")
                        
                        # åŸºäºå…¨æ–‡æåŠæ¬¡æ•°è°ƒæ•´ç›¸å…³æ€§åˆ†æ•°
                        if mentions > 0:
                            article['relevance']['score'] += mentions * 5
                        
                        processed_count += 1
                    else:
                        # æ— æ³•è·å–å…¨æ–‡ï¼ˆå¯èƒ½æ²¡æœ‰PMC IDæˆ–å…¨æ–‡ä¸å¯ç”¨ï¼‰
                        pmid = article.get('pmid', 'N/A')
                        pmc_id = article.get('pmc_id', '')
                        
                        if not pmc_id:
                            print(f"[{idx}/{max_process}] âš ï¸ PMID {pmid}: æ— PMC IDï¼Œæ— æ³•è·å–å…¨æ–‡")
                        else:
                            print(f"[{idx}/{max_process}] âš ï¸ {pmc_id}: å…¨æ–‡ä¸å¯ç”¨æˆ–è§£æå¤±è´¥")
                        
                        article['has_fulltext'] = False
                        article['pmc_available'] = bool(pmc_id)
                        
                except Exception as e:
                    print(f"[{idx}/{max_process}] âŒ PMID {article.get('pmid', 'N/A')}: å¤„ç†å¤±è´¥ - {e}")
                    article['has_fulltext'] = False
                    article['pmc_available'] = bool(article.get('pmc_id'))
            
            print(f"\nâœ… å®Œæˆè¯¦ç»†åˆ†æ: {processed_count}/{max_process} ç¯‡\n")
        
        # ğŸ”§ ä¿®å¤ï¼šç»Ÿè®¡å·²å°è¯•å¤„ç†å’ŒæˆåŠŸè·å–çš„æ•°é‡
        attempted_count = sum(1 for a in articles if a.get('fulltext_processed', False))
        fulltext_count = sum(1 for a in articles if a.get('has_fulltext', False))
        
        print(f"{'='*60}")
        print(f"æœç´¢å®Œæˆ:")
        print(f"  æ€»æ–‡ç« æ•°: {len(articles)}")
        print(f"  å·²å°è¯•å¤„ç†: {attempted_count}") 
        print(f"  æˆåŠŸè·å–å…¨æ–‡: {fulltext_count}")
        if len(articles) >= page_size:
            print(f"  âš ï¸  ç»“æœå¯èƒ½è¢«æˆªæ–­ï¼ˆè¾¾åˆ°{page_size}ç¯‡ä¸Šé™ï¼‰")
        print(f"{'='*60}\n")
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ä¸Šé™
        is_truncated = len(articles) >= page_size
        
        return jsonify({
            "keyword": keyword,
            "total": len(articles),
            "processed": attempted_count if fetch_fulltext else 0,  # âœ… ä¿®å¤ï¼šè¿”å›å·²å°è¯•å¤„ç†çš„æ•°é‡
            "fulltext_available": fulltext_count,  # æˆåŠŸè·å–å…¨æ–‡çš„æ•°é‡
            "search_method": "Europe PMC Full-Text Search",
            "is_truncated": is_truncated,
            "page_size": page_size,
            "results": articles
        })
        
    except Exception as e:
        print(f"æœç´¢é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/api/retry-failed', methods=['POST'])
def retry_failed():
    """
    é‡æ–°å¤„ç†å¤±è´¥çš„æ–‡ç« 
    
    è¯·æ±‚ä½“: {articles: [å¤±è´¥çš„æ–‡ç« åˆ—è¡¨], keyword}
    è¿”å›: {processed, failed, results}
    """
    try:
        data = request.get_json()
        failed_articles = data.get('articles', [])
        keyword = data.get('keyword', '')
        
        if not failed_articles:
            return jsonify({"processed": 0, "failed": 0, "results": []})
        
        print(f"\n{'='*60}")
        print(f"é‡æ–°å¤„ç†å¤±è´¥çš„æ–‡ç« : å…± {len(failed_articles)} ç¯‡")
        print(f"{'='*60}\n")
        
        pmc_fetcher = PMCFetcher()
        processed_articles = []
        processed_count = 0
        still_failed = 0
        
        for idx, article in enumerate(failed_articles, 1):
            # ä¿®æ”¹ï¼šä¸å†ç›´æ¥è·³è¿‡æ²¡æœ‰ pmc_id çš„æ–‡ç« 
            # å°è¯•é€šè¿‡ PMID è·å–
            article['fulltext_processed'] = True
            
            try:
                fulltext_info = pmc_fetcher.get_fulltext_info(article['pmid'], keyword)
                
                if fulltext_info and fulltext_info.get('fulltext'):
                    # æˆåŠŸè·å–å…¨æ–‡
                    article['fulltext'] = fulltext_info['fulltext']
                    article['has_fulltext'] = True
                    article['pmc_id'] = fulltext_info.get('pmc_id') or article.get('pmc_id')
                    article['pmc_available'] = True
                    article['fulltext_error'] = None
                    
                    mentions = fulltext_info['fulltext']['total_mentions']
                    pmc_id = article.get('pmc_id', 'N/A')
                    print(f"[{idx}/{len(failed_articles)}] âœ… {pmc_id}: é‡è¯•æˆåŠŸï¼Œæ‰¾åˆ° {mentions} å¤„æåŠ")
                    
                    if mentions > 0:
                        article['relevance']['score'] += mentions * 5
                    
                    processed_count += 1
                else:
                    # é‡è¯•å¤±è´¥
                    pmid = article.get('pmid', 'N/A')
                    pmc_id = article.get('pmc_id', '')
                    
                    if not pmc_id:
                        print(f"[{idx}/{len(failed_articles)}] âš ï¸ PMID {pmid}: æ— PMC ID")
                        article['fulltext_error'] = 'NO_PMC_ID'
                    else:
                        print(f"[{idx}/{len(failed_articles)}] âš ï¸ {pmc_id}: å…¨æ–‡ä¸å¯ç”¨")
                        article['fulltext_error'] = 'FETCH_FAILED'
                    
                    article['has_fulltext'] = False
                    article['pmc_available'] = bool(pmc_id)
                    still_failed += 1
                    
            except Exception as e:
                print(f"[{idx}/{len(failed_articles)}] âŒ PMID {article.get('pmid', 'N/A')}: é‡è¯•å‡ºé”™ - {e}")
                article['fulltext_error'] = str(e)
                article['has_fulltext'] = False
                article['pmc_available'] = bool(article.get('pmc_id'))
                still_failed += 1
            
            processed_articles.append(article)
        
        print(f"\nâœ… é‡è¯•å®Œæˆ: æˆåŠŸ {processed_count} ç¯‡ï¼Œä»å¤±è´¥ {still_failed} ç¯‡\n")
        
        return jsonify({
            "processed": processed_count,
            "failed": still_failed,
            "results": processed_articles
        })
    
    except Exception as e:
        print(f"é‡è¯•é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/api/continue-fulltext', methods=['POST'])
def continue_fulltext():
    """
    ç»§ç»­å¤„ç†æ›´å¤šæ–‡ç« çš„è¯¦ç»†å…¨æ–‡ï¼ˆæ¸è¿›å¼åŠ è½½ï¼‰
    
    è¯·æ±‚ä½“: {articles: [å¾…å¤„ç†çš„æ–‡ç« åˆ—è¡¨], keyword}
    è¿”å›: {processed, results}
    """
    try:
        data = request.get_json()
        articles_to_process = data.get('articles', [])
        keyword = data.get('keyword', '')
        
        if not keyword:
            return jsonify({"error": "å…³é”®è¯ä¸èƒ½ä¸ºç©º"}), 400
        
        if not articles_to_process:
            return jsonify({
                "processed": 0,
                "results": []
            })
        
        print(f"\n{'='*60}")
        print(f"ç»§ç»­å¤„ç†å…¨æ–‡: {keyword}")
        print(f"å¾…å¤„ç†æ–‡ç« æ•°: {len(articles_to_process)}")
        print(f"{'='*60}\n")
        
        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æ–‡ç« åˆ—è¡¨ï¼Œä¸å†é‡æ–°æœç´¢ï¼
        target_articles = articles_to_process
        
        # å¤„ç†å…¨æ–‡
        pmc_fetcher = PMCFetcher()
        processed_articles = []
        processed_count = 0
        
        for idx, article in enumerate(target_articles, 1):
            # ä¿®æ”¹ï¼šä¸å†ç›´æ¥è·³è¿‡æ²¡æœ‰ pmc_id çš„æ–‡ç« 
            article['fulltext_processed'] = True
            
            try:
                fulltext_info = pmc_fetcher.get_fulltext_info(article['pmid'], keyword)
                
                if fulltext_info and fulltext_info.get('fulltext'):
                    # æˆåŠŸè·å–å…¨æ–‡
                    article['fulltext'] = fulltext_info['fulltext']
                    article['has_fulltext'] = True
                    article['pmc_id'] = fulltext_info.get('pmc_id') or article.get('pmc_id')
                    article['pmc_available'] = True
                    
                    mentions = fulltext_info['fulltext']['total_mentions']
                    pmc_id = article.get('pmc_id', 'N/A')
                    print(f"[{idx}/{len(target_articles)}] âœ… {pmc_id}: æ‰¾åˆ° {mentions} å¤„æåŠ")
                    
                    if mentions > 0:
                        article['relevance']['score'] += mentions * 5
                    
                    processed_count += 1
                else:
                    # æ— æ³•è·å–å…¨æ–‡
                    pmid = article.get('pmid', 'N/A')
                    pmc_id = article.get('pmc_id', '')
                    
                    if not pmc_id:
                        print(f"[{idx}/{len(target_articles)}] âš ï¸ PMID {pmid}: æ— PMC ID")
                    else:
                        print(f"[{idx}/{len(target_articles)}] âš ï¸ {pmc_id}: å…¨æ–‡ä¸å¯ç”¨")
                    
                    article['has_fulltext'] = False
                    article['pmc_available'] = bool(pmc_id)
                    
            except Exception as e:
                print(f"[{idx}/{len(target_articles)}] âŒ PMID {article.get('pmid', 'N/A')}: å¤„ç†å¤±è´¥ - {e}")
                article['has_fulltext'] = False
                article['pmc_available'] = bool(article.get('pmc_id'))
            
            # æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½è¿”å›æ–‡ç« 
            processed_articles.append(article)
        
        print(f"\nâœ… å®Œæˆå¢é‡å¤„ç†: {processed_count}/{len(target_articles)} ç¯‡\n")
        
        return jsonify({
            "processed": processed_count,
            "results": processed_articles
        })
    
    except Exception as e:
        print(f"é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


def analyze_relevance(article: Dict, keyword: str) -> Dict:
    """
    åˆ†ææ–‡ç« ä¸å…³é”®è¯çš„ç›¸å…³æ€§
    
    Returns:
        {
            "score": ç›¸å…³æ€§åˆ†æ•°,
            "mentions": å…³é”®è¯å‡ºç°ä½ç½®åˆ—è¡¨,
            "context": å…³é”®è¯ä¸Šä¸‹æ–‡ç‰‡æ®µ
        }
    """
    title = article.get('title', '').lower()
    abstract = article.get('abstract', '').lower()
    keyword_lower = keyword.lower()
    
    score = 0
    mentions = []
    contexts = []
    
    # åœ¨æ ‡é¢˜ä¸­å‡ºç°ï¼Œåˆ†æ•°æ›´é«˜
    if keyword_lower in title:
        score += 50
        mentions.append("title")
    
    # åœ¨æ‘˜è¦ä¸­æŸ¥æ‰¾å…³é”®è¯
    if keyword_lower in abstract:
        score += 30
        mentions.append("abstract")
        
        # æå–å…³é”®è¯å‘¨å›´çš„ä¸Šä¸‹æ–‡
        pattern = re.compile(f'.{{0,100}}{re.escape(keyword_lower)}.{{0,100}}', re.IGNORECASE)
        matches = pattern.findall(article.get('abstract', ''))
        contexts = [match.strip() for match in matches[:3]]  # æœ€å¤š3ä¸ªä¸Šä¸‹æ–‡
    
    return {
        "score": score,
        "mentions": mentions,
        "contexts": contexts
    }

@app.route('/api/article/<pmid>', methods=['GET'])
def get_article_detail(pmid: str):
    """
    è·å–å•ç¯‡æ–‡ç« çš„è¯¦ç»†ä¿¡æ¯
    """
    try:
        searcher = PubMedSearcher()
        articles = searcher.fetch_article_details([pmid])
        
        if articles:
            return jsonify(articles[0])
        else:
            return jsonify({"error": "æ–‡ç« æœªæ‰¾åˆ°"}), 404
            
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ==================== é¡¹ç›®ç®¡ç†API ====================

@app.route('/api/projects', methods=['POST'])
def create_project():
    """
    åˆ›å»ºæ–°é¡¹ç›®
    
    è¯·æ±‚ä½“: {name, keyword, years, description (å¯é€‰)}
    è¿”å›: {project_id, message}
    """
    try:
        data = request.get_json()
        name = data.get('name', '')
        keyword = data.get('keyword', '')
        years = data.get('years', 3)
        description = data.get('description', '')
        
        if not name or not keyword:
            return jsonify({"error": "é¡¹ç›®åç§°å’Œå…³é”®è¯ä¸èƒ½ä¸ºç©º"}), 400
        
        project_id = db.create_project(name, keyword, years, description)
        
        return jsonify({
            "project_id": project_id,
            "message": "é¡¹ç›®åˆ›å»ºæˆåŠŸ"
        })
    
    except Exception as e:
        print(f"åˆ›å»ºé¡¹ç›®é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/api/projects', methods=['GET'])
def list_projects():
    """
    è·å–é¡¹ç›®åˆ—è¡¨
    
    æŸ¥è¯¢å‚æ•°: limit (é»˜è®¤50), offset (é»˜è®¤0)
    è¿”å›: {projects: [...]}
    """
    try:
        limit = request.args.get('limit', 50, type=int)
        offset = request.args.get('offset', 0, type=int)
        
        projects = db.list_projects(limit, offset)
        
        return jsonify({
            "projects": projects,
            "count": len(projects)
        })
    
    except Exception as e:
        print(f"è·å–é¡¹ç›®åˆ—è¡¨é”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/projects/<project_id>', methods=['GET'])
def get_project(project_id: str):
    """
    è·å–é¡¹ç›®è¯¦æƒ…å’Œæ‰€æœ‰æ–‡ç« 
    
    è¿”å›: {project: {...}, articles: [...]}
    """
    try:
        result = db.load_project(project_id)
        
        if result is None:
            return jsonify({"error": "é¡¹ç›®æœªæ‰¾åˆ°"}), 404
        
        return jsonify(result)
    
    except Exception as e:
        print(f"åŠ è½½é¡¹ç›®é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/api/projects/<project_id>', methods=['PUT'])
def update_project(project_id: str):
    """
    æ›´æ–°é¡¹ç›®å…ƒæ•°æ®
    
    è¯·æ±‚ä½“: {name (å¯é€‰), description (å¯é€‰)}
    è¿”å›: {message}
    """
    try:
        data = request.get_json()
        name = data.get('name')
        description = data.get('description')
        
        success = db.update_project_metadata(project_id, name, description)
        
        if success:
            return jsonify({"message": "é¡¹ç›®æ›´æ–°æˆåŠŸ"})
        else:
            return jsonify({"error": "é¡¹ç›®æœªæ‰¾åˆ°æˆ–æ— æ›´æ–°"}), 404
    
    except Exception as e:
        print(f"æ›´æ–°é¡¹ç›®é”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/projects/<project_id>', methods=['DELETE'])
def delete_project(project_id: str):
    """
    åˆ é™¤é¡¹ç›®åŠæ‰€æœ‰ç›¸å…³æ–‡ç« 
    
    è¿”å›: {message}
    """
    try:
        success = db.delete_project(project_id)
        
        if success:
            return jsonify({"message": "é¡¹ç›®åˆ é™¤æˆåŠŸ"})
        else:
            return jsonify({"error": "é¡¹ç›®æœªæ‰¾åˆ°"}), 404
    
    except Exception as e:
        print(f"åˆ é™¤é¡¹ç›®é”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/projects/<project_id>/articles', methods=['POST'])
def save_project_articles(project_id: str):
    """
    ä¿å­˜æ–‡ç« åˆ°é¡¹ç›®ï¼ˆæ‰¹é‡ä¿å­˜/æ›´æ–°ï¼‰
    
    è¯·æ±‚ä½“: {articles: [...]}
    è¿”å›: {saved_count, message}
    """
    try:
        data = request.get_json()
        articles = data.get('articles', [])
        
        if not articles:
            return jsonify({"error": "æ–‡ç« åˆ—è¡¨ä¸èƒ½ä¸ºç©º"}), 400
        
        saved_count = db.save_articles(project_id, articles)
        
        # è·å–æ›´æ–°åçš„ç»Ÿè®¡ä¿¡æ¯
        stats = db.get_project_stats(project_id)
        
        return jsonify({
            "saved_count": saved_count,
            "message": f"æˆåŠŸä¿å­˜ {saved_count} ç¯‡æ–‡ç« ",
            "stats": stats
        })
    
    except Exception as e:
        print(f"ä¿å­˜æ–‡ç« é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/api/projects/<project_id>/stats', methods=['GET'])
def get_project_statistics(project_id: str):
    """
    è·å–é¡¹ç›®ç»Ÿè®¡ä¿¡æ¯
    
    è¿”å›: {project_id, name, total_articles, processed_articles, ...}
    """
    try:
        stats = db.get_project_stats(project_id)
        
        if stats is None:
            return jsonify({"error": "é¡¹ç›®æœªæ‰¾åˆ°"}), 404
        
        return jsonify(stats)
    
    except Exception as e:
        print(f"è·å–ç»Ÿè®¡ä¿¡æ¯é”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 500


if __name__ == '__main__':
    print("Starting FigureScout API Server...")
    print("API available at: http://localhost:5000")
    app.run(debug=True, host='0.0.0.0', port=5000)

